{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1e9fe2b9-bdcc-452c-9f8d-5ebdd4372898",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run /Workspace/Users/kianhow2000@gmail.com/Databricks/01_Data_Engineer_Learning_Plan/Lab-Setup/common-utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9b4bfca6-d284-411d-9231-94a5214fb53c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "\n",
    "import json, random, base64, time\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "CATALOG = \"workspace\"\n",
    "SCHEMA_PREFIX = \"data_engineering_labs\"\n",
    "VOLUME = \"v01\"\n",
    "\n",
    "RUN_ID = get_run_id(default=\"00\")              # uses widgets: run_id=00\n",
    "SCHEMA = f\"{SCHEMA_PREFIX}_{RUN_ID}\"           # data_engineering_labs_00\n",
    "\n",
    "OUT_DIR_REL = \"raw/events-kafka\"\n",
    "NUM_FILES = 11            # 000..010\n",
    "EVENTS_PER_FILE = 500     # tweak if you want bigger/smaller\n",
    "PARTITIONS = 3            # will vary partitions 0..2\n",
    "TOPIC = \"clickstream\"\n",
    "\n",
    "BASE_OFFSET = 219255030   # like your sample\n",
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "\n",
    "banner(f\"Setting up Kafka-esque events in {CATALOG}.{SCHEMA}\")\n",
    "\n",
    "ensure_catalog_and_schema(CATALOG, SCHEMA)\n",
    "VOLUME_ROOT = ensure_volume(CATALOG, SCHEMA, VOLUME)\n",
    "\n",
    "OUT_DIR = f\"{VOLUME_ROOT}/{OUT_DIR_REL}\"\n",
    "dbutils.fs.mkdirs(OUT_DIR)\n",
    "\n",
    "print(\"Output dir:\", OUT_DIR)\n",
    "print(f\"Writing {NUM_FILES} files x {EVENTS_PER_FILE} events/file = {NUM_FILES*EVENTS_PER_FILE} total events\")\n",
    "\n",
    "# -----------------------------\n",
    "# Variation pools\n",
    "# -----------------------------\n",
    "DEVICES = [\"Android\", \"iOS\", \"Web\", \"Windows\", \"MacOS\"]\n",
    "EVENT_NAMES = [\"main\", \"product_view\", \"add_to_cart\", \"begin_checkout\", \"purchase\", \"search\"]\n",
    "TRAFFIC = [\"google\", \"facebook\", \"instagram\", \"tiktok\", \"email\", \"direct\", \"referral\", \"bing\"]\n",
    "\n",
    "# City/state combos\n",
    "GEO = [\n",
    "    (\"New York\", \"NY\"),\n",
    "    (\"San Francisco\", \"CA\"),\n",
    "    (\"Seattle\", \"WA\"),\n",
    "    (\"Austin\", \"TX\"),\n",
    "    (\"Chicago\", \"IL\"),\n",
    "    (\"Boston\", \"MA\"),\n",
    "    (\"Miami\", \"FL\"),\n",
    "    (\"Los Angeles\", \"CA\"),\n",
    "    (\"Denver\", \"CO\"),\n",
    "    (\"Singapore\", \"SG\"),\n",
    "]\n",
    "\n",
    "ITEM_CATALOG = [\n",
    "    (\"M_STAN_K\", \"Standard King Mattress\", 1195.0),\n",
    "    (\"M_STAN_Q\", \"Standard Queen Mattress\", 995.0),\n",
    "    (\"M_STAN_F\", \"Standard Full Mattress\", 849.0),\n",
    "    (\"P_BASIC\", \"Basic Pillow\", 59.0),\n",
    "    (\"B_FRAME_Q\", \"Queen Bed Frame\", 399.0),\n",
    "    (\"SHEET_K\", \"King Sheet Set\", 129.0),\n",
    "]\n",
    "\n",
    "COUPONS = [None, \"NEWBED10\", \"SLEEP5\", \"WELCOME15\", \"FREESHIP\", None, None]\n",
    "\n",
    "def rand_key(n=14):\n",
    "    # \"encoded-looking\" (base32-ish alphabet)\n",
    "    alphabet = \"ABCDEFGHJKLMNPQRSTUVWXYZ23456789\"\n",
    "    return \"\".join(random.choice(alphabet) for _ in range(n))\n",
    "\n",
    "def rand_user_id():\n",
    "    # UA + digits\n",
    "    return \"UA\" + \"\".join(str(random.randint(0,9)) for _ in range(10))\n",
    "\n",
    "def make_items_and_ecommerce():\n",
    "    # 0..3 items; if 0 items => no purchase revenue\n",
    "    k = random.choices([0,1,2,3], weights=[20,45,25,10], k=1)[0]\n",
    "    chosen = random.sample(ITEM_CATALOG, k=k) if k > 0 else []\n",
    "\n",
    "    items = []\n",
    "    total_qty = 0\n",
    "    unique_items = len(chosen)\n",
    "    revenue = 0.0\n",
    "\n",
    "    for (item_id, item_name, price) in chosen:\n",
    "        qty = random.randint(1, 2)\n",
    "        coupon = random.choice(COUPONS)\n",
    "        # simulate discount a bit\n",
    "        discount = 0.0\n",
    "        if coupon in (\"NEWBED10\", \"SLEEP5\"):\n",
    "            discount = 0.05 if coupon == \"SLEEP5\" else 0.10\n",
    "        if coupon == \"WELCOME15\":\n",
    "            discount = 0.15\n",
    "\n",
    "        item_rev = round(price * qty * (1.0 - discount), 2)\n",
    "        revenue += item_rev\n",
    "        total_qty += qty\n",
    "\n",
    "        items.append({\n",
    "            \"coupon\": coupon,\n",
    "            \"item_id\": item_id,\n",
    "            \"item_name\": item_name,\n",
    "            \"item_revenue_in_usd\": item_rev,\n",
    "            \"price_in_usd\": price,\n",
    "            \"quantity\": qty\n",
    "        })\n",
    "\n",
    "    ecommerce = {\n",
    "        \"purchase_revenue_in_usd\": round(revenue, 2),\n",
    "        # keep your field spelling as given (total_item_quantity)\n",
    "        \"total_item_quantity\": int(total_qty),\n",
    "        \"unique_items\": int(unique_items),\n",
    "    }\n",
    "    return items, ecommerce\n",
    "\n",
    "def b64_encode_json(obj: dict) -> str:\n",
    "    payload = json.dumps(obj, separators=(\",\", \":\"), ensure_ascii=False)\n",
    "    return base64.b64encode(payload.encode(\"utf-8\")).decode(\"utf-8\")\n",
    "\n",
    "# Base timestamps (so data looks realistic and consistent)\n",
    "now_ms = int(time.time() * 1000)\n",
    "base_event_ts = now_ms - (7 * 24 * 3600 * 1000)  # ~7 days ago\n",
    "\n",
    "# -----------------------------\n",
    "# Generate and write JSONL files\n",
    "# -----------------------------\n",
    "offset = BASE_OFFSET\n",
    "\n",
    "for file_idx in range(NUM_FILES):\n",
    "    file_name = f\"{file_idx:03d}.json\"\n",
    "    file_path = f\"{OUT_DIR}/{file_name}\"\n",
    "\n",
    "    lines = []\n",
    "    for i in range(EVENTS_PER_FILE):\n",
    "        user_id = rand_user_id()\n",
    "        device = random.choice(DEVICES)\n",
    "        event_name = random.choice(EVENT_NAMES)\n",
    "        traffic_source = random.choice(TRAFFIC)\n",
    "        city, state = random.choice(GEO)\n",
    "\n",
    "        # clickstream payload timestamps\n",
    "        event_timestamp = base_event_ts + random.randint(0, 7*24*3600*1000)   # ms-ish\n",
    "        user_first_touch = event_timestamp - random.randint(1, 180) * 24*3600*1000\n",
    "\n",
    "        items, ecommerce = make_items_and_ecommerce()\n",
    "\n",
    "        # If no purchase revenue, keep event_name less likely to be purchase\n",
    "        if ecommerce[\"purchase_revenue_in_usd\"] == 0.0 and event_name == \"purchase\":\n",
    "            event_name = random.choice([\"main\", \"product_view\", \"search\", \"add_to_cart\"])\n",
    "\n",
    "        clickstream = {\n",
    "            \"device\": device,\n",
    "            \"ecommerce\": ecommerce,\n",
    "            \"event_name\": event_name,\n",
    "            # keep as integer (as in your example). Use a \"big\" number style:\n",
    "            \"event_timestamp\": int(event_timestamp) * 100000 + random.randint(0, 99999),\n",
    "            \"geo\": {\"city\": city, \"state\": state},\n",
    "            \"items\": items,\n",
    "            # keep your field spelling: \"traffic_source\" (3 f's)\n",
    "            \"traffic_source\": traffic_source,\n",
    "            \"user_first_touch_timestamp\": int(user_first_touch),\n",
    "            \"user_id\": user_id\n",
    "        }\n",
    "\n",
    "        envelope = {\n",
    "            \"key\": rand_key(14),\n",
    "            \"offset\": int(offset),\n",
    "            \"partition\": int(offset % PARTITIONS),\n",
    "            \"timestamp\": int(event_timestamp),  # epoch ms\n",
    "            \"topic\": TOPIC,\n",
    "            \"value\": b64_encode_json(clickstream)\n",
    "        }\n",
    "\n",
    "        lines.append(json.dumps(envelope, separators=(\",\", \":\")))\n",
    "        offset += 1\n",
    "\n",
    "    # Write as a single JSONL file\n",
    "    dbutils.fs.rm(file_path, True)\n",
    "    dbutils.fs.put(file_path, \"\\n\".join(lines) + \"\\n\", overwrite=True)\n",
    "\n",
    "print(\"âœ… Done writing files:\", [f.name for f in dbutils.fs.ls(OUT_DIR)])\n",
    "\n",
    "# -----------------------------\n",
    "# Quick verification: decode one record\n",
    "# -----------------------------\n",
    "sample_file = f\"{OUT_DIR}/000.json\"\n",
    "first_line = dbutils.fs.head(sample_file, 5000).splitlines()[0]\n",
    "outer = json.loads(first_line)\n",
    "decoded = json.loads(base64.b64decode(outer[\"value\"]).decode(\"utf-8\"))\n",
    "\n",
    "print(\"\\nSample outer JSON keys:\", list(outer.keys()))\n",
    "print(\"Sample decoded clickstream keys:\", list(decoded.keys()))\n",
    "print(\"\\nSample decoded clickstream (pretty):\")\n",
    "print(json.dumps(decoded, indent=2))\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "lab-setup-05",
   "widgets": {}
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
