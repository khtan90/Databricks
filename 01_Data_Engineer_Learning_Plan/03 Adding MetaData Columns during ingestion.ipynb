{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b2bfde3-a734-4ca5-9354-2c4d752737c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Lesson:\n",
    "- In this lesson, we will learn how to add metadata columns during ingestion\n",
    "\n",
    "### Objectives\n",
    "- Modify columns durin data ingestion from cloud stroage to bronze table\n",
    "- Add current ingestion timestamp to the bronze\n",
    "- Use the _metadata column to extract the file-level metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6f3b376c-e97f-4cae-9273-6f1648df4219",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 01 Setup:\n",
    "- We will be using the same data from \"01 Data Ingestion with CREATE TABLE AS and COPY INTO\" lab\n",
    "- If not already created,. Run `%run ../01_Data_Engineer_Learning_Plan/Lab-Setup/lab-setup-01 `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe908c98-6e21-4e9a-a87c-b18ce09b8ff2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- View the files in our volume that shoudl contain our parquet files\n",
    "LIST '/Volumes/workspace/data_engineering_labs_00/v01/raw/users-historical/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1220375c-c23f-4ae9-9246-0504a601f3d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 02 Adding MetaData columns to the Bronze Table during Ingestion\n",
    "- To include the '_metadata' column, we have to explicitly select it in the read query\n",
    "- Lets also try to:\n",
    "  1. Convert parquet timestamp to a DATE column\n",
    "  2. Include input file name \n",
    "  3. Include last modification timestamp\n",
    "  4. Add file ingestion time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68d080e0-1ad2-43ec-b83c-26d5377b51d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- READ sample data form our parquet files\n",
    "SELECT * \n",
    "FROM read_files(\n",
    "  '/Volumes/workspace/data_engineering_labs_00/v01/raw/users-historical',\n",
    "  format => 'parquet'\n",
    ")\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "de182210-aa6c-4097-aef3-29ec6ddf47e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- Use `from_unixtime()` function to create a readable date column\n",
    "- Also divide by 10000000 to change from microseconds to seconds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3399b188-6cbe-4739-81e3-16c49383a442",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "--- Convert Unixtime on ingestion to Bronze\n",
    "SELECT *,\n",
    "CAST(from_unixtime(user_first_touch_timestamp/1000000) AS DATE) as first_touch_date\n",
    "FROM read_files(\n",
    "  '/Volumes/workspace/data_engineering_labs_00/v01/raw/users-historical',\n",
    "  format => 'parquet'\n",
    ")\n",
    "LIMIT 10;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "004048a2-42b0-4fc7-923e-a34d748bf7f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- We can add these metadata\n",
    "  - `_.metadta.file_modification`\n",
    "  - `_.metadta.file_name`\n",
    "  - `current_timestamp()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a89961ab-1072-419d-9e36-fb842c56ee0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT *,\n",
    "CAST(from_unixtime(user_first_touch_timestamp/1000000) AS DATE) as first_touch_date,\n",
    "_metadata.file_name as file_name,\n",
    "_metadata.file_modification_time as file_modification_time,\n",
    "current_timestamp() as ingestion_time\n",
    "FROM read_files(\n",
    "  '/Volumes/workspace/data_engineering_labs_00/v01/raw/users-historical',\n",
    "  format => 'parquet'\n",
    ")\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c320503b-a107-470c-9071-9b6662eefe5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Put it all together, we can create our Bronze Delta Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb3aabd8-6a94-449d-b773-e1c6e2c24404",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- DROP Table and recreate\n",
    "DROP TABLE IF EXISTS historical_users_bronze;\n",
    "\n",
    "-- Create empoty table\n",
    "CREATE TABLE historical_users_bronze AS \n",
    "\n",
    "SELECT *,\n",
    "CAST(from_unixtime(user_first_touch_timestamp/1000000) AS DATE) as first_touch_date,\n",
    "_metadata.file_name as file_name,\n",
    "_metadata.file_modification_time as file_modification_time,\n",
    "current_timestamp() as ingestion_time\n",
    "FROM read_files(\n",
    "  '/Volumes/workspace/data_engineering_labs_00/v01/raw/users-historical',\n",
    "  format => 'parquet'\n",
    ");\n",
    "\n",
    "-- View final bronze table\n",
    "SELECT * FROM historical_users_bronze LIMIT 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b61f85b4-1873-4374-9a67-68cb841746dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Optional Exploration\n",
    "- Count how many rows came form each parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1642e1a2-2b34-4517-9dd4-10eda8422098",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT\n",
    "file_name as source_file, count(*) as total\n",
    "FROM historical_users_bronze\n",
    "GROUP BY source_file\n",
    "ORDER BY source_file DESC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "af3a888a-2ded-4504-b3b4-6d482b294bfe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Python Equivalent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "453675cd-eec9-4b04-9044-ab1c297eae74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "from pyspark.sql.functions import col, from_unixtime, current_timestamp\n",
    "from pyspark.sql.types import DateType\n",
    "\n",
    "# Read parquet\n",
    "df = spark.read.format(\"parquet\").load('/Volumes/workspace/data_engineering_labs_00/v01/raw/users-historical')\n",
    "\n",
    "## Add Metadata columns\n",
    "df_with_metadata = df.withColumn(\"first_touch_date\", from_unixtime(col(\"user_first_touch_timestamp\")/1000000).cast(DateType()))\\\n",
    ".withColumn(\"file_modification_time\", col(\"_metadata.file_modification_time\"))\\\n",
    ".withColumn(\"source_file\", col(\"_metadata.file_name\"))\\\n",
    ".withColumn(\"ingestion_time\", current_timestamp())\n",
    "\n",
    "# Save as delta table\n",
    "df_with_metadata.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"workspace.data_engineering_labs_00.users_historical_bronze_python_metadata\")\n",
    "\n",
    "#Raed and display table\n",
    "users_historical_bronze_python_metadata = spark.table(\"workspace.data_engineering_labs_00.users_historical_bronze_python_metadata\")\n",
    "display(users_historical_bronze_python_metadata)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03 Adding MetaData Columns during ingestion",
   "widgets": {}
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
